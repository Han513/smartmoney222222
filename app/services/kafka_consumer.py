# app/services/kafka_consumer.py

import json
import asyncio
import logging
from typing import Dict, Any, List, Optional
from aiokafka import AIOKafkaConsumer
from datetime import datetime
import time
import uuid

from app.core.config import settings
from app.services.cache_service import cache_service

# è¨­ç½® Kafka ç›¸é—œæ—¥èªŒç´šåˆ¥ï¼Œæ¸›å°‘ä¸å¿…è¦çš„è­¦å‘Š
logging.getLogger("aiokafka.consumer.fetcher").setLevel(logging.WARNING)
logging.getLogger("aiokafka.consumer.group_coordinator").setLevel(logging.WARNING)
logging.getLogger("aiokafka.consumer").setLevel(logging.WARNING)
logging.getLogger("aiokafka").setLevel(logging.WARNING)

logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

class KafkaConsumerService:
    """
    Kafka æ¶ˆè²»è€…æœå‹™ - è² è²¬è¨‚é–±Kafkaäº‹ä»¶ä¸¦ä¿å­˜åˆ°ç·©å­˜ä¸­
    """
    
    def __init__(self):
        self.consumer = None
        self.topic = settings.KAFKA_TOPIC
        self.bootstrap_servers = settings.KAFKA_BOOTSTRAP_SERVERS
        # åˆå§‹åŒ–æ™‚ä¸ç”Ÿæˆ group_idï¼Œåœ¨ start æ–¹æ³•ä¸­ç”Ÿæˆ
        self.group_id = None
        self.running = False
        self.task = None
        self.cache_key_prefix = "kafka_msg:"
        self.message_queue_key = "kafka_message_queue"
        self.processing_queue_key = "kafka_processing_queue"
        self.max_retries = 5  # å¢åŠ é‡è©¦æ¬¡æ•¸
        self.connection_retry_count = 0
        self.max_connection_retries = 10
    
    async def start(self):
        """å•Ÿå‹• Kafka æ¶ˆè²»è€…æœå‹™"""
        if self.running:
            logger.info("Kafka æ¶ˆè²»è€…æœå‹™å·²åœ¨é‹è¡Œä¸­")
            return True
        
        # ç”Ÿæˆå‹•æ…‹ group_idï¼Œæ¯æ¬¡å•Ÿå‹•éƒ½å¾æœ€æ–°æ¶ˆæ¯é–‹å§‹æ¶ˆè²»
        timestamp = int(time.time())
        self.group_id = f"{settings.KAFKA_GROUP_ID}_{timestamp}"
        logger.info(f"ğŸ¯ ç”Ÿæˆå‹•æ…‹æ¶ˆè²»è€…çµ„ ID: {self.group_id} (æ™‚é–“æˆ³: {timestamp})")
        logger.info(f"ğŸ”„ æ¯æ¬¡é‡å•Ÿéƒ½å°‡å¾æœ€æ–° Kafka æ¶ˆæ¯é–‹å§‹æ¶ˆè²»")
            
        logger.info(f"å•Ÿå‹• Kafka æ¶ˆè²»è€…æœå‹™ï¼Œé€£æ¥åˆ° {self.bootstrap_servers}, ä¸»é¡Œ: {self.topic}, æ¶ˆè²»è€…çµ„: {self.group_id}")
        
        # å˜—è©¦é€£æ¥ï¼Œå¦‚æœå¤±æ•—å‰‡é‡è©¦
        for attempt in range(self.max_connection_retries):
            try:
                await self._create_and_start_consumer()
                self.connection_retry_count = 0  # é‡ç½®é‡è©¦è¨ˆæ•¸
                return True
            except Exception as e:
                self.connection_retry_count += 1
                logger.error(f"å•Ÿå‹• Kafka æ¶ˆè²»è€…æœå‹™å¤±æ•— (å˜—è©¦ {self.connection_retry_count}/{self.max_connection_retries}): {e}")
                
                if self.connection_retry_count >= self.max_connection_retries:
                    logger.critical(f"é”åˆ°æœ€å¤§é€£æ¥é‡è©¦æ¬¡æ•¸ï¼Œåœæ­¢å˜—è©¦")
                    return False
                
                # æŒ‡æ•¸é€€é¿é‡è©¦
                wait_time = min(2 ** self.connection_retry_count, 60)  # æœ€å¤šç­‰å¾…60ç§’
                logger.info(f"ç­‰å¾… {wait_time} ç§’å¾Œé‡è©¦é€£æ¥...")
                await asyncio.sleep(wait_time)
        
        return False
    
    async def _create_and_start_consumer(self):
        """å‰µå»ºä¸¦å•Ÿå‹•æ¶ˆè²»è€…"""
        # è¨­ç½®æ¶ˆè²»è€…é…ç½®ï¼Œå„ªåŒ–è™•ç†æ€§èƒ½åƒæ•¸å’Œé€£æ¥ç©©å®šæ€§
        consumer_config = {
            'bootstrap_servers': self.bootstrap_servers,
            'group_id': self.group_id,
            'auto_offset_reset': "latest",  # æ–°æ¶ˆè²»è€…çµ„å¾æœ€æ–°æ¶ˆæ¯é–‹å§‹
            'value_deserializer': lambda m: json.loads(m.decode('utf-8')),
            'enable_auto_commit': False,
            
            # å¢åŠ è¶…æ™‚æ™‚é–“ï¼Œæé«˜é€£æ¥ç©©å®šæ€§
            'request_timeout_ms': 60000,  # å¢åŠ åˆ°60ç§’
            'session_timeout_ms': 60000,  # å¢åŠ åˆ°60ç§’
            'heartbeat_interval_ms': 10000,  # å¢åŠ åˆ°10ç§’ï¼Œæ¸›å°‘å¿ƒè·³é »ç‡
            'max_poll_interval_ms': 600000,  # å¢åŠ åˆ°10åˆ†é˜æœ€å¤§è¼ªè©¢é–“éš”
            
            # æ¸›å°‘æ¯æ¬¡è¼ªè©¢çš„è¨˜éŒ„æ•¸ï¼Œé¿å…è™•ç†æ™‚é–“éé•·
            'max_poll_records': 5,  # é€²ä¸€æ­¥æ¸›å°‘åˆ°5æ¢
            
            # å„ªåŒ–fetché…ç½®
            'fetch_max_wait_ms': 1000,  # å¢åŠ åˆ°1ç§’
            'fetch_min_bytes': 1,
            'fetch_max_bytes': 524288,  # æ¸›å°‘åˆ°512KB
            
            # å…¶ä»–å„ªåŒ–
            'check_crcs': False,  # é—œé–‰CRCæª¢æŸ¥ä»¥æé«˜æ€§èƒ½
            'isolation_level': "read_committed"
        }
        
        logger.info(f"Kafka æ¶ˆè²»è€…é…ç½®: {consumer_config}")
        
        self.consumer = AIOKafkaConsumer(
            self.topic,
            **consumer_config
        )
        
        await self.consumer.start()
        self.running = True
        logger.info("Kafka æ¶ˆè²»è€…æœå‹™å·²å•Ÿå‹•")
        
        # å‰µå»ºç•°æ­¥ä»»å‹™ä¾†è™•ç†æ¶ˆæ¯
        self.task = asyncio.create_task(self._consume_messages())
    
    async def stop(self):
        """åœæ­¢ Kafka æ¶ˆè²»è€…æœå‹™"""
        if not self.running:
            return
            
        logger.info("åœæ­¢ Kafka æ¶ˆè²»è€…æœå‹™")
        self.running = False
        
        if self.task:
            self.task.cancel()
            try:
                await self.task
            except asyncio.CancelledError:
                pass
            
        if self.consumer:
            try:
                await self.consumer.stop()
            except Exception as e:
                logger.warning(f"åœæ­¢æ¶ˆè²»è€…æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
        logger.info("Kafka æ¶ˆè²»è€…æœå‹™å·²åœæ­¢")
    
    async def _consume_messages(self):
        """æ¶ˆè²» Kafka æ¶ˆæ¯çš„ä¸»å¾ªç’° - åƒ…å°‡æ¶ˆæ¯ä¿å­˜åˆ°ç·©å­˜"""
        try:
            logger.info("é–‹å§‹æ¶ˆè²» Kafka æ¶ˆæ¯")
            
            # åˆå§‹åŒ–é‡è©¦è¨ˆæ•¸å™¨
            retry_count = 0
            backoff_time = 1.0  # åˆå§‹é€€é¿æ™‚é–“ï¼ˆç§’ï¼‰
            
            while self.running:
                try:
                    # å¾Kafkaç²å–æ¶ˆæ¯
                    async for msg in self.consumer:
                        try:
                            # è§£ææ¶ˆæ¯
                            event_data = msg.value
                            
                            # æª¢æŸ¥æ˜¯å¦æ˜¯æˆ‘å€‘æœŸæœ›çš„æ ¼å¼
                            if not self._validate_event(event_data):
                                # logger.warning(f"æ”¶åˆ°ç„¡æ•ˆçš„äº‹ä»¶æ ¼å¼: {event_data}")
                                await self.consumer.commit()
                                continue
                            
                            # ç”Ÿæˆå”¯ä¸€IDç”¨æ–¼è·Ÿè¸ªæ¶ˆæ¯
                            message_id = str(uuid.uuid4())
                            
                            # å°‡æ¶ˆæ¯ä¿å­˜åˆ°ç·©å­˜
                            await self._cache_message(message_id, event_data)
                            
                            # å°‡æ¶ˆæ¯IDæ·»åŠ åˆ°è™•ç†éšŠåˆ—
                            await self._add_to_processing_queue(message_id)
                            
                            # æäº¤ä½ç§»
                            await self.consumer.commit()
                            
                            # é‡ç½®é‡è©¦è¨ˆæ•¸å™¨
                            retry_count = 0
                            backoff_time = 1.0
                            
                        except Exception as e:
                            logger.exception(f"è™•ç† Kafka æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                            # å°æ–¼ CommitFailedErrorï¼Œä¸æäº¤ä½ç§»ï¼Œè®“æ¶ˆæ¯é‡æ–°è™•ç†
                            if "CommitFailedError" in str(e) or "IllegalGenerationError" in str(e):
                                logger.warning("æª¢æ¸¬åˆ°ä½ç§»æäº¤å¤±æ•—ï¼Œè·³éæäº¤ä»¥é¿å…é‡è¤‡è™•ç†")
                                continue
                            # å…¶ä»–éŒ¯èª¤ä»ç„¶æäº¤ä½ç§»ï¼Œé¿å…åŒä¸€æ¢æ¶ˆæ¯åè¦†è™•ç†
                            try:
                                await self.consumer.commit()
                            except Exception as commit_error:
                                logger.error(f"æäº¤ä½ç§»å¤±æ•—: {commit_error}")
                    
                except asyncio.CancelledError:
                    logger.info("æ¶ˆæ¯æ¶ˆè²»ä»»å‹™è¢«å–æ¶ˆ")
                    raise
                    
                except Exception as e:
                    retry_count += 1
                    error_msg = str(e)
                    logger.error(f"æ¶ˆè²» Kafka æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤ (å˜—è©¦ {retry_count}/{self.max_retries}): {e}")
                    
                    # æª¢æŸ¥æ˜¯å¦æ˜¯é€£æ¥ç›¸é—œéŒ¯èª¤
                    if any(keyword in error_msg for keyword in [
                        "RequestTimedOutError", "ConnectionError", "NetworkError",
                        "IllegalGenerationError", "UnknownMemberIdError", "CommitFailedError"
                    ]):
                        logger.warning("æª¢æ¸¬åˆ°é€£æ¥éŒ¯èª¤ï¼Œç«‹å³é‡å•Ÿæ¶ˆè²»è€…")
                        retry_count = 0
                        await self._restart_consumer()
                        continue
                    
                    if retry_count >= self.max_retries:
                        logger.critical(f"é”åˆ°æœ€å¤§é‡è©¦æ¬¡æ•¸ ({self.max_retries})ï¼Œå°‡é‡å•Ÿæ¶ˆè²»è€…")
                        retry_count = 0
                        await self._restart_consumer()
                    else:
                        # ä½¿ç”¨æŒ‡æ•¸é€€é¿ç­–ç•¥
                        wait_time = backoff_time
                        backoff_time = min(backoff_time * 2, 60)  # æœ€å¤šç­‰å¾…60ç§’
                        logger.info(f"ç­‰å¾… {wait_time:.1f} ç§’å¾Œé‡è©¦...")
                        await asyncio.sleep(wait_time)
                        
        except asyncio.CancelledError:
            logger.info("æ¶ˆæ¯æ¶ˆè²»ä»»å‹™è¢«å–æ¶ˆ")
            raise
        except Exception as e:
            logger.exception(f"æ¶ˆè²» Kafka æ¶ˆæ¯æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            if self.running:
                logger.info("å˜—è©¦é‡æ–°å•Ÿå‹•æ¶ˆè²»è€…...")
                await asyncio.sleep(5)
                self.task = asyncio.create_task(self._consume_messages())
    
    async def _restart_consumer(self):
        """é‡å•ŸKafkaæ¶ˆè²»è€…"""
        # é‡æ–°ç”Ÿæˆ group_idï¼Œç¢ºä¿å¾æœ€æ–°æ¶ˆæ¯é–‹å§‹æ¶ˆè²»
        timestamp = int(time.time())
        self.group_id = f"{settings.KAFKA_GROUP_ID}_{timestamp}"
        logger.info(f"ğŸ”„ é‡å•Ÿ Kafka æ¶ˆè²»è€…ï¼Œæ–°çš„æ¶ˆè²»è€…çµ„: {self.group_id} (æ™‚é–“æˆ³: {timestamp})")
        
        try:
            if self.consumer:
                try:
                    await self.consumer.stop()
                except Exception as stop_error:
                    logger.warning(f"åœæ­¢èˆŠæ¶ˆè²»è€…æ™‚ç™¼ç”ŸéŒ¯èª¤: {stop_error}")
            
            # ç­‰å¾…ä¸€æ®µæ™‚é–“ç¢ºä¿èˆŠé€£æ¥å®Œå…¨é—œé–‰
            await asyncio.sleep(3)
            
            # é‡æ–°å‰µå»ºæ¶ˆè²»è€…
            await self._create_and_start_consumer()
            logger.info("Kafka æ¶ˆè²»è€…å·²é‡å•Ÿ")
            
        except Exception as e:
            logger.exception(f"é‡å•Ÿ Kafka æ¶ˆè²»è€…å¤±æ•—: {e}")
            # å¦‚æœé‡å•Ÿå¤±æ•—ï¼Œç­‰å¾…æ›´é•·æ™‚é–“å¾Œå†å˜—è©¦
            await asyncio.sleep(15)
    
    def _validate_event(self, event_data: Dict[str, Any]) -> bool:
        """é©—è­‰äº‹ä»¶æ ¼å¼"""
        try:
            # æª¢æŸ¥å¿…è¦å­—æ®µ
            if "event" not in event_data:
                return False
            
            event = event_data["event"]
            required_fields = [
                "network", "tokenAddress", "side", "txnValue", 
                "address", "hash", "price", "timestamp"
            ]
            
            for field in required_fields:
                if field not in event:
                    logger.warning(f"äº‹ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")
                    return False
            
            # ç¢ºèªæ˜¯ SOLANA ç¶²çµ¡
            if event["network"] != "SOLANA":
                logger.info(f"è·³éé SOLANA ç¶²çµ¡äº‹ä»¶: {event['network']}")
                return False
                
            return True
        except Exception as e:
            logger.error(f"é©—è­‰äº‹ä»¶æ ¼å¼å‡ºéŒ¯: {e}")
            return False
    
    async def _cache_message(self, message_id: str, message_data: Dict[str, Any]):
        """å°‡æ¶ˆæ¯ä¿å­˜åˆ°ç·©å­˜"""
        try:
            # æª¢æŸ¥æ˜¯å¦å·²ç¶“è™•ç†éç›¸åŒçš„äº¤æ˜“ï¼ˆåŸºæ–¼signatureå»é‡ï¼‰
            event = message_data.get("event", {})
            signature = event.get("hash")
            
            if signature:
                # æª¢æŸ¥æ˜¯å¦å·²ç¶“è™•ç†éé€™å€‹signature
                existing_message = await cache_service.get(f"processed_signature:{signature}")
                if existing_message:
                    logger.info(f"è·³éé‡è¤‡çš„signature: {signature}")
                    return True
            
            # æ·»åŠ å…ƒæ•¸æ“š
            message_with_metadata = {
                "id": message_id,
                "data": message_data,
                "status": "pending",
                "created_at": int(time.time()),
                "retries": 0,
                "last_error": None
            }
            
            # ä¿å­˜åˆ°ç·©å­˜ï¼Œè¨­ç½®24å°æ™‚éæœŸæ™‚é–“ï¼ˆæ¸›å°‘Rediså…§å­˜ä½”ç”¨ï¼‰
            await cache_service.set(
                f"{self.cache_key_prefix}{message_id}", 
                message_with_metadata,
                expiry=24 * 3600  # 24å°æ™‚éæœŸ
            )
            
            # å¦‚æœsignatureå­˜åœ¨ï¼Œè¨˜éŒ„å·²è™•ç†çš„signatureï¼ˆè¨­ç½®è¼ƒçŸ­çš„éæœŸæ™‚é–“ï¼Œé¿å…è¨˜æ†¶é«”æ´©æ¼ï¼‰
            if signature:
                await cache_service.set(
                    f"processed_signature:{signature}",
                    {"processed_at": int(time.time())},
                    expiry=3600  # 1å°æ™‚éæœŸ
                )
            
            # logger.info(f"æ¶ˆæ¯ {message_id} å·²ä¿å­˜åˆ°ç·©å­˜")
            return True
        except Exception as e:
            logger.error(f"ä¿å­˜æ¶ˆæ¯åˆ°ç·©å­˜å¤±æ•—: {e}")
            return False
    
    async def _add_to_processing_queue(self, message_id: str):
        """å°‡æ¶ˆæ¯IDæ·»åŠ åˆ°è™•ç†éšŠåˆ—"""
        try:
            # å°‡æ¶ˆæ¯IDæ·»åŠ åˆ°éšŠåˆ—ï¼ˆä½¿ç”¨Redisåˆ—è¡¨ï¼‰
            await cache_service.add_to_list(self.message_queue_key, message_id)
            logger.debug(f"æ¶ˆæ¯ {message_id} å·²æ·»åŠ åˆ°è™•ç†éšŠåˆ—")
            return True
        except Exception as e:
            logger.error(f"æ·»åŠ æ¶ˆæ¯åˆ°è™•ç†éšŠåˆ—å¤±æ•—: {e}")
            return False

# å‰µå»ºå…¨å±€å¯¦ä¾‹
kafka_consumer = KafkaConsumerService()